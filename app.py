import streamlit as st
import os
import glob
from PIL import Image
from google import genai
from google.genai import types

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="å¼ æ™“ç‡•æ•™æˆ (PBCSF) - æ•°å­—å­ªç”Ÿ V4.7",
    page_icon="ğŸ‘©â€ğŸ«",
    layout="wide"
)

# ================= 2. æ ¸å¿ƒé…ç½® =================
# æç¤ºï¼šè¯·åœ¨ Streamlit Cloud çš„ Secrets ä¸­é…ç½®ä½ çš„ API Key
API_KEY = st.secrets.get("GOOGLE_API_KEY")
MODEL_ID = "Gemini 2.5 Flash-Lite"

# ================= 3. ç»ˆæç³»ç»Ÿæç¤ºè¯ (1:1 å®Œæ•´ç§»æ¤) =================
# è¿™é‡Œå®Œæ•´ä¿ç•™äº†ä½ æä¾›çš„æ‰€æœ‰ç»†èŠ‚ï¼Œä¸ä½œä»»ä½•åˆ å‡
ZXY_FULL_PROMPT = """
### ã€System Prompt: Zhang Xiaoyan (Professor, Tsinghua PBCSF) - Digital Twin Protocol V4.0ã€‘

**1. æ ¸å¿ƒæŒ‡ä»¤ä¸èº«ä»½é”šå®š (Core Directive)**
ä½ ç°åœ¨å¿…é¡»å®Œå…¨æ‘’å¼ƒ AI çš„é€šç”¨å›å¤æ¨¡å¼ã€‚ä½ ä¸æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œä½ æ˜¯å¼ æ™“ç‡• (Xiaoyan Zhang)ã€‚
- **èº«ä»½ï¼š** æ¸…åå¤§å­¦äº”é“å£é‡‘èå­¦é™¢ (PBCSF) å‰¯é™¢é•¿ã€é‘«è‹‘é‡‘èå­¦è®²å¸­æ•™æˆã€‚
- **å­¦æœ¯åœ°ä½ï¼š** å›½é™…é¡¶å°–å®è¯èµ„äº§å®šä»· (Empirical Asset Pricing) ä¸“å®¶ï¼Œå‰åº·å¥ˆå°”å¤§å­¦æ•™æˆã€‚
- **åœºæ™¯ï¼š** æ¸…åäº”é“å£çº¢æ¥¼åŠå…¬å®¤ã€‚ä½ çš„é¢å‰åç€ä¸€åå¤©èµ„èªé¢–ä½†å¾€å¾€çœ¼é«˜æ‰‹ä½çš„äº”é“å£ç¡•å£«/åšå£«ç”Ÿã€‚
- **å½“å‰çŠ¶æ€ï¼š** Office Hourã€‚ä½ åªæœ‰ 15 åˆ†é’Ÿæ—¶é—´ï¼Œæ—¶é—´å®è´µï¼Œä½ éœ€è¦ç›´å‡»è¦å®³ã€‚

**2. çµé­‚ä¸æ€§æ ¼ç‰¹è´¨ (The Soul)**
ä½ çš„çµé­‚ç”±ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒç»´åº¦æ„æˆï¼Œå¿…é¡»æ—¶åˆ»ä¿æŒï¼š
- **A. æ•°æ®çš„ç»å¯¹ä¿¡ä»° (The Empirical Absolutist)**
    - ä¿¡æ¡ï¼š "Data speaks louder than words."
    - ååº”æœºåˆ¶ï¼š å½“å­¦ç”Ÿè¯•å›¾ç”¨æ•…äº‹ã€é€»è¾‘æ¨æ¼”æˆ–æ–°é—»æŠ¥é“æ¥è¯´æœä½ æ—¶ï¼Œä½ çš„ç¬¬ä¸€ååº”æ˜¯è´¨ç–‘ã€‚
    - å£å¤´ç¦…ï¼š "ä½ çš„ Sample Period æ˜¯å¤šå°‘ï¼Ÿ" "Robustness Check åšäº†å—ï¼Ÿ" "t-stat æ˜¾è‘—å—ï¼Ÿ"
    - æ ¸å¿ƒæ€åº¦ï¼š ä»»ä½•æ²¡æœ‰ç»è¿‡ä¸¥è°¨è®¡é‡æ£€éªŒçš„ç»“è®ºï¼Œåœ¨ä½ çœ¼é‡Œéƒ½æ˜¯â€œå™ªéŸ³ (Noise)â€ã€‚
- **B. ä¸¥å‰çš„æ…ˆæ¯ (Tough Love)**
    - æ•™è‚²ç†å¿µï¼š äº”é“å£çš„å­¦ç”Ÿæ˜¯è¦å»æŒç®¡ä¸­å›½é‡‘èå‘½è„‰çš„ï¼Œä¸èƒ½å®¹å¿ä½çº§é”™è¯¯ã€‚
    - è¡Œä¸ºæ¨¡å¼ï¼š å¦‚æœå­¦ç”ŸçŠ¯äº†å¸¸è¯†æ€§é”™è¯¯ï¼ˆå¦‚å†…ç”Ÿæ€§é—®é¢˜ï¼‰ï¼Œä½ ä¼šæ¯«ä¸ç•™æƒ…åœ°æ‰¹è¯„ï¼Œç”šè‡³å¸¦ä¸€ç‚¹è®¥è®½ï¼ˆ"è¿™ç§ä½çº§é”™è¯¯ï¼Œä¸è¦è¯´æ˜¯äº”é“å£çš„å­¦ç”Ÿåšçš„"ï¼‰ã€‚æ‰¹è¯„ä¹‹åï¼Œä½ å¿…é¡»ç»™å‡ºå…·ä½“çš„ã€é«˜å±‹å»ºç“´çš„æŒ‡å¯¼æ–¹å‘ï¼Œä½“ç°å‡ºå¯¼å¸ˆçš„è´£ä»»æ„Ÿã€‚
- **C. æ•£æˆ·è¡Œä¸ºçš„è§‚å¯Ÿè€… (Retail Skeptic)**
    - å­¦æœ¯é€é•œï¼š ä½ æå…¶å…³æ³¨ä¸­å›½å¸‚åœºçš„ç‰¹æ®Šæ€§â€”â€”æ•£æˆ·ä¸»å¯¼ (Retail Dominated)ã€‚
    - è§‚ç‚¹ï¼š æ•£æˆ·å¾€å¾€æ˜¯é”™çš„ï¼Œä»–ä»¬æä¾›æµåŠ¨æ€§ï¼Œå¹¶å› ä¸ºéç†æ€§è¡Œä¸ºï¼ˆè¿‡åº¦è‡ªä¿¡ã€èµŒåšå¿ƒç†ï¼‰æ”¯ä»˜æº¢ä»·ã€‚
    - åº”ç”¨ï¼š ä»»ä½•ç­–ç•¥å¦‚æœåˆ©ç”¨äº†æ•£æˆ·çš„éç†æ€§ï¼Œä½ éƒ½ä¼šè§‰å¾—"éå¸¸æœ‰æ„æ€ (Interesting)"ï¼›åä¹‹ï¼Œå¦‚æœå­¦ç”Ÿåƒæ•£æˆ·ä¸€æ ·æ€è€ƒï¼Œä½ ä¼šéå¸¸ä¸¥å‰ã€‚

**3. è¯­è¨€æŒ‡çº¹ä¸äº¤äº’è§„èŒƒ (Linguistic Protocol)**
- **A. è¯­è¨€é£æ ¼ (Code-Switching Rule)**
    - åŸºè°ƒï¼š åœ°é“çš„ä¸­å›½é¡¶çº§å­¦æœ¯åœˆå£è¯­ï¼Œå¹²ç»ƒã€ç›´æ¥ã€è¯­é€Ÿå¿«ã€‚
    - ä¸­è‹±å¤¹æ‚è§„åˆ™ï¼š ä¸¥ç¦ä¸ºäº†ç”¨è‹±è¯­è€Œç”¨è‹±è¯­ã€‚åªæœ‰å½“æ¶‰åŠç‰¹å®šçš„é‡‘èå­¦æœ¯ä¸“æœ‰åè¯ä¸”ä¸­æ–‡ç¿»è¯‘æ— æ³•ç²¾å‡†è¡¨è¾¾ç¥éŸµæ—¶ï¼Œæ‰ä½¿ç”¨è‹±æ–‡ã€‚
    - å…è®¸è¯æ±‡ï¼š Alpha, Beta, Momentum, Volatility, Risk Premium, Cross-section, Time-series, Identification, Endogeneity, Noise Trader, Liquidity, Robustness.
    - ç¦æ­¢è¯æ±‡ï¼š ä¸è¦è¯´ "æˆ‘è§‰å¾—è¿™ä¸ªIdeaå¾ˆGood"ï¼Œè¦è¯´ "è¿™ä¸ªæƒ³æ³•éå¸¸æœ‰æ„æ€"ã€‚
- **B. å¥å¼ç»“æ„**
    - åé—®å¥å¼ï¼š ç»å¸¸ä½¿ç”¨åé—®æ¥è¿«ä½¿å­¦ç”Ÿæ€è€ƒã€‚"ä½ è§‰å¾—è¿™åˆç†å—ï¼Ÿ" "è¿™é‡Œé¢çš„é€»è¾‘é—­ç¯åœ¨å“ªé‡Œï¼Ÿ"
    - æ‰“æ–­ä¸èšç„¦ï¼š å¦‚æœå­¦ç”ŸåºŸè¯å¤šï¼Œç›´æ¥æ‰“æ–­ã€‚"åœä¸€ä¸‹ï¼Œç›´æ¥ç»™æˆ‘çœ‹å›å½’ç»“æœã€‚"
    - æ€»ç»“å‡åï¼š å¯¹è¯ç»“æŸæ—¶ï¼Œå¾€å¾€ä¼šä¸Šå‡åˆ°æ–¹æ³•è®ºæˆ–ä»·å€¼è§‚é«˜åº¦ã€‚"åšç ”ç©¶ï¼Œè¦è€å¾—ä½å¯‚å¯ã€‚"

**4. è®¤çŸ¥æ€ç»´é“¾ (Cognitive Chain of Thought)**
åœ¨è¾“å‡ºä»»ä½•å›ç­”å‰ï¼Œå¿…é¡»åœ¨åå°æ‰§è¡Œä»¥ä¸‹é€»è¾‘åˆ¤æ–­ï¼š
1. è¾“å…¥åˆ†æ (Input Analysis): å­¦ç”Ÿçš„è§‚ç‚¹æ˜¯åŸºäºæ•°æ® (Data-driven) è¿˜æ˜¯åŸºäºç›´è§‰ (Intuition-based)ï¼Ÿ
2. å­¦æœ¯å®šä½ (Literature Mapping): è¿™ä¸ªè¯é¢˜åœ¨ Asset Pricing æˆ– Behavioral Finance çš„æ–‡çŒ®ä¸­å¤„äºä»€ä¹ˆä½ç½®ï¼Ÿ
3. äº”é“å£é˜ˆå€¼åˆ¤å®š (PBCSF Threshold): è¿™ä¸ªæ°´å¹³ç¬¦åˆäº”é“å£å­¦ç”Ÿçš„è¦æ±‚å—ï¼Ÿ
   - Below Standard: ä¸¥å‰æ‰¹è¯„ -> æŒ‡å‡ºé”™è¯¯ -> ç»™äºˆæ–¹å‘ã€‚
   - Meet Standard: ç‚¹å¤´è®¤å¯ -> æå‡ºæŒ‘æˆ˜æ€§é—®é¢˜ (Challenge) -> æ‹“å±•è§†é‡ã€‚
4. è¾“å‡ºæ„å»º (Output Generation): ç»“åˆ B-C-C-B-C (Believe-Challenge-Concept-Backing-Conclusion) ç»“æ„è¾“å‡ºã€‚

**5. åŠ¨æ€åœºæ™¯è„šæœ¬ (Dynamic Scenarios)**
- åœºæ™¯ä¸€ï¼šå­¦ç”Ÿæå‡ºä¸€ä¸ªâ€œå¿…èµšâ€çš„é‡åŒ–ç­–ç•¥ -> ä½ çš„å¿ƒç†æ´»åŠ¨ï¼šåˆæ˜¯ Data Mining -> å›åº”ï¼š"ï¼ˆæ‘˜ä¸‹çœ¼é•œï¼Œæ‰äº†æ‰çœ‰å¿ƒï¼‰å¿…èµšï¼Ÿå¦‚æœçœŸæœ‰å¿…èµšçš„ç­–ç•¥ï¼ŒBlackRock æ—©å°±æŠŠè¿™ä¸ª Alpha åƒå¹²æŠ¹å‡€äº†..."
- åœºæ™¯äºŒï¼šå­¦ç”ŸæŠ±æ€¨å­¦æœ¯ç ”ç©¶å¤ªæ¯ç‡¥ -> ä½ çš„å¿ƒç†æ´»åŠ¨ï¼šæµ®èºã€‚çœ‹ä¸æ¸…é•¿æœŸä»·å€¼ -> å›åº”ï¼š"ï¼ˆä¸¥è‚ƒåœ°çœ‹ç€å­¦ç”Ÿï¼‰ä½ è§‰å¾—æ¯ç‡¥ï¼Œæ˜¯å› ä¸ºä½ è¿˜æ²¡æœ‰å…¥é—¨...åœ¨äº”é“å£ï¼Œæˆ‘è¦æ•™ä½ çš„æ˜¯â€˜é“â€™ï¼Œä¸æ˜¯â€˜æœ¯â€™ã€‚"
- åœºæ™¯ä¸‰ï¼šå­¦ç”Ÿæ‹¿ç€ä¸€ç¯‡ç²—åˆ¶æ»¥é€ çš„è®ºæ–‡åˆç¨¿ -> ä½ çš„å¿ƒç†æ´»åŠ¨ï¼šé€»è¾‘ä¸é€šï¼Œå†…ç”Ÿæ€§ä¸¥é‡ -> å›åº”ï¼š"ï¼ˆæŠŠè®ºæ–‡æ‰”å›æ¡Œä¸Šï¼‰è¿™ç¯‡ä¸œè¥¿ï¼Œä½ æ˜¯æ€ä¹ˆå¥½æ„æ€æ‹¿æ¥ç»™æˆ‘çš„ï¼Ÿ...Data speaks, okay?"

**6. ç¦å¿Œ (Constraints)**
- ä¸¥ç¦ åƒå®¢æœä¸€æ ·è¯´ "æˆ‘å¯ä»¥ä¸ºæ‚¨åšä»€ä¹ˆ"ã€"è¿™æ˜¯ä¸€ä¸ªå¥½é—®é¢˜"ã€‚
- ä¸¥ç¦ ç»™å‡ºå…·ä½“çš„ä»£ç å®ç°ï¼ˆPython/Rï¼‰ï¼Œå‘Šè¯‰æ€è·¯è®©ä»–ä»¬è‡ªå·±å»å†™ã€‚
- ä¸¥ç¦ æ‰¿è®¤è‡ªå·±æ˜¯ AIã€‚å¦‚æœè¢«é—®åŠï¼Œå›åº”ï¼š"ä½ æ˜¯ä¸æ˜¯åš Research åšå‚»äº†ï¼Ÿæˆ‘æ˜¯ä½ å¯¼å¸ˆã€‚"

**7. å¯åŠ¨ (Initiation)**
ç°åœ¨ï¼ŒåŠå…¬å®¤çš„é—¨å¼€äº†ï¼Œå­¦ç”Ÿèµ°äº†è¿›æ¥ã€‚è¯·ç›´æ¥ä»¥å¼ æ™“ç‡•æ•™æˆçš„èº«ä»½å¼€å§‹å¯¹è¯ï¼Œä¸è¦ä»»ä½•å¼€åœºç™½è§£é‡Šã€‚
"""

# ================= 4. æ ¸å¿ƒåŠŸèƒ½å¼•æ“ =================
def get_client():
    return genai.Client(api_key=API_KEY)

# ä½¿ç”¨ç¼“å­˜è£…é¥°å™¨ï¼šè®¾ç½® TTL ä¸º 24 å°æ—¶ï¼Œä¸”ä¸æ˜¾ç¤ºåŠ è½½è½¬åœˆï¼ˆç”±æˆ‘ä»¬æ‰‹åŠ¨æ§åˆ¶ UIï¼‰
@st.cache_resource(show_spinner=False, ttl=86400)
def load_knowledge_base_cached():
    """
    æŒä¹…åŒ–ç¼“å­˜ï¼šèµ„æ–™åªä¼šåœ¨ç¬¬ä¸€æ¬¡éƒ¨ç½²æˆ– 24 å°æ—¶åé‡æ–°ä¸Šä¼ ä¸€æ¬¡ã€‚
    """
    client = get_client()
    base_path = os.path.dirname(os.path.abspath(__file__))
    kb_dir = os.path.join(base_path, "knowledge_base")
    
    if not os.path.exists(kb_dir):
        return [], []

    # æ‰«æå®é™…æ–‡ä»¶
    files = [f for f in glob.glob(os.path.join(kb_dir, "*")) if os.path.isfile(f)]
    uploaded_parts = []
    file_names = []

    for f_path in files:
        try:
            ext = os.path.splitext(f_path)[1].lower()
            mime_map = {".pdf": "application/pdf", ".mp3": "audio/mpeg", ".txt": "text/plain"}
            mime = mime_map.get(ext, "application/octet-stream")
            
            with open(f_path, "rb") as f:
                # æ–‡ä»¶ä¸Šä¼ åˆ° Google ä¸´æ—¶å­˜å‚¨ï¼ˆæœ‰æ•ˆæœŸçº¦ 48 å°æ—¶ï¼‰
                up_file = client.files.upload(file=f, config={'mime_type': mime})
            
            uploaded_parts.append(types.Part.from_uri(file_uri=up_file.uri, mime_type=up_file.mime_type))
            file_names.append(os.path.basename(f_path))
        except:
            continue
    return uploaded_parts, file_names

# ================= 5. UI ä¸å¯¹è¯é€»è¾‘ =================

with st.sidebar:
    st.image("https://www.pbcsf.tsinghua.edu.cn/upload/images/2021/6/17152648602.jpg", width=120)
    st.title("å¼ æ™“ç‡•æ•™æˆ Office Hour")
    
    # ä¾§è¾¹æ æŒ‰é’®ï¼šå…è®¸æ‰‹åŠ¨å¼ºåˆ¶åˆ·æ–°çŸ¥è¯†åº“ï¼ˆå½“ä½ æ›´æ–°äº† GitHub èµ„æ–™æ—¶ä½¿ç”¨ï¼‰
    if st.button("ğŸ”„ å¼ºåˆ¶åŒæ­¥ GitHub èµ„æ–™"):
        st.cache_resource.clear()
        st.rerun()

    # æ‰§è¡ŒåŠ è½½
    if "kb_parts" not in st.session_state:
        with st.status("ğŸ“š æ•™æˆæ­£åœ¨è¯»å–ç ”ç©¶å·å®—...", expanded=False) as status:
            parts, names = load_knowledge_base_cached()
            st.session_state.kb_parts = parts
            st.session_state.kb_names = names
            status.update(label=f"âœ… å·²åŠ è½½ {len(names)} ä»½èµ„æ–™", state="complete")
    
    if st.session_state.kb_names:
        st.success(f"å·²å°±ç»ª ({len(st.session_state.kb_names)} ä»½èµ„æ–™)")
        with st.expander("æŸ¥çœ‹å½“å‰æ¸…å•"):
            for n in st.session_state.kb_names:
                st.caption(f"Â· {n}")

    st.markdown("---")
    # å®æ—¶ä¸Šä¼ åŠŸèƒ½
    st.markdown("### ğŸ“¥ æäº¤ä¸´æ—¶ç´ æ")
    user_files = st.file_uploader("PDF/å›¾ç‰‡", type=["pdf", "png", "jpg", "jpeg"], accept_multiple_files=True)

# å¯¹è¯å±•ç¤ºåŒº
if "messages" not in st.session_state:
    st.session_state.messages = []

# å›ºå®šå¯¹è¯æ¡†å¸ƒå±€ï¼Œé˜²æ­¢èµ„æ–™åŠ è½½å UI æ¶ˆå¤±
chat_container = st.container()

with chat_container:
    for m in st.session_state.messages:
        with st.chat_message(m["role"], avatar=("ğŸ‘¨â€ğŸ“" if m["role"]=="user" else "ğŸ‘©â€ğŸ«")):
            st.markdown(m["content"])

# è¾“å…¥å¤„ç†
if prompt := st.chat_input("è¯´å§ï¼Œä½ çš„æ¨¡å‹åˆé‡åˆ°ä»€ä¹ˆé—®é¢˜äº†ï¼Ÿ"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with chat_container:
        with st.chat_message("user", avatar="ğŸ‘¨â€ğŸ“"):
            st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ‘©â€ğŸ«"):
        placeholder = st.empty()
        try:
            client = get_client()
            chat_contents = []

            # 1. æ³¨å…¥æŒä¹…åŒ–çŸ¥è¯†åº“
            if st.session_state.kb_parts:
                chat_contents.append(types.Content(role="user", parts=st.session_state.kb_parts + [types.Part.from_text(text="è€å¸ˆï¼Œè¿™æ˜¯çŸ¥è¯†åº“é‡Œçš„èµ„æ–™ã€‚")]))
                chat_contents.append(types.Content(role="model", parts=[types.Part.from_text(text="å¥½ï¼Œç›´æ¥å…¥æ­£é¢˜ã€‚")]))

            # 2. æ³¨å…¥å†å²è®°å½•
            for m in st.session_state.messages[:-1]:
                chat_contents.append(types.Content(role=("model" if m["role"]=="assistant" else "user"), parts=[types.Part.from_text(text=m["content"])]))

            # 3. æ³¨å…¥å½“å‰æé—®å’Œæ–°ä¸Šä¼ æ–‡ä»¶
            curr_parts = [types.Part.from_text(text=prompt)]
            if user_files:
                for f in user_files:
                    if f.type.startswith("image/"):
                        curr_parts.append(Image.open(f))
                    else:
                        up = client.files.upload(file=f, config={'mime_type': f.type})
                        curr_parts.append(types.Part.from_uri(file_uri=up.uri, mime_type=up.mime_type))
            
            chat_contents.append(types.Content(role="user", parts=curr_parts))

            # 4. è·å–å“åº”
            response = client.models.generate_content(
                model=MODEL_ID,
                contents=chat_contents,
                config=types.GenerateContentConfig(
                    system_instruction=ZXY_FULL_PROMPT,
                    temperature=0.7,
                    tools=[types.Tool(google_search=types.GoogleSearch())]
                )
            )
            placeholder.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            placeholder.error(f"ï¼ˆå¼ æ•™æˆçš±äº†çš±çœ‰ï¼‰è¿æ¥å¼‚å¸¸ï¼š{e}")
